2022-01-17 01:02:10,072 - INFO - allennlp.common.params - random_seed = 0
2022-01-17 01:02:10,072 - INFO - allennlp.common.params - numpy_seed = 0
2022-01-17 01:02:10,072 - INFO - allennlp.common.params - pytorch_seed = 0
2022-01-17 01:02:10,073 - INFO - allennlp.common.checks - Pytorch version: 1.7.0
2022-01-17 01:02:10,073 - INFO - allennlp.common.params - type = default
2022-01-17 01:02:10,074 - INFO - allennlp.common.params - dataset_reader.type = span_model
2022-01-17 01:02:10,074 - INFO - allennlp.common.params - dataset_reader.lazy = False
2022-01-17 01:02:10,074 - INFO - allennlp.common.params - dataset_reader.cache_directory = None
2022-01-17 01:02:10,074 - INFO - allennlp.common.params - dataset_reader.max_instances = None
2022-01-17 01:02:10,075 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False
2022-01-17 01:02:10,075 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False
2022-01-17 01:02:10,075 - INFO - allennlp.common.params - dataset_reader.max_span_width = 8
2022-01-17 01:02:10,075 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched
2022-01-17 01:02:10,075 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0
2022-01-17 01:02:10,076 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = bert-base-uncased
2022-01-17 01:02:10,076 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags
2022-01-17 01:02:10,076 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512
2022-01-17 01:02:10,076 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None
2022-01-17 01:02:10,728 - INFO - allennlp.common.params - train_data_path = /content/SSA-SemEval/Span-ASTE-main/model_outputs/aste_darmstadt_unis_6e01f1772af7bbbef56b8ba0511d931f/train.json
2022-01-17 01:02:10,729 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7fb31aa14ed0>
2022-01-17 01:02:10,729 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-01-17 01:02:10,729 - INFO - allennlp.common.params - validation_dataset_reader = None
2022-01-17 01:02:10,729 - INFO - allennlp.common.params - validation_data_path = /content/SSA-SemEval/Span-ASTE-main/model_outputs/aste_darmstadt_unis_6e01f1772af7bbbef56b8ba0511d931f/dev.json
2022-01-17 01:02:10,729 - INFO - allennlp.common.params - validation_data_loader = None
2022-01-17 01:02:10,729 - INFO - allennlp.common.params - test_data_path = /content/SSA-SemEval/Span-ASTE-main/model_outputs/aste_darmstadt_unis_6e01f1772af7bbbef56b8ba0511d931f/test.json
2022-01-17 01:02:10,730 - INFO - allennlp.common.params - evaluate_on_test = False
2022-01-17 01:02:10,730 - INFO - allennlp.common.params - batch_weight_key = 
2022-01-17 01:02:10,730 - INFO - allennlp.training.util - Reading training data from /content/SSA-SemEval/Span-ASTE-main/model_outputs/aste_darmstadt_unis_6e01f1772af7bbbef56b8ba0511d931f/train.json
2022-01-17 01:02:10,730 - INFO - tqdm - reading instances: 0it [00:00, ?it/s]
2022-01-17 01:02:20,733 - INFO - tqdm - reading instances: 1017it [00:10, 112.32it/s]
2022-01-17 01:02:30,808 - INFO - tqdm - reading instances: 2208it [00:20, 128.02it/s]
2022-01-17 01:02:31,141 - INFO - allennlp.training.util - Reading validation data from /content/SSA-SemEval/Span-ASTE-main/model_outputs/aste_darmstadt_unis_6e01f1772af7bbbef56b8ba0511d931f/dev.json
2022-01-17 01:02:31,141 - INFO - tqdm - reading instances: 0it [00:00, ?it/s]
2022-01-17 01:02:32,913 - INFO - allennlp.training.util - Reading test data from /content/SSA-SemEval/Span-ASTE-main/model_outputs/aste_darmstadt_unis_6e01f1772af7bbbef56b8ba0511d931f/test.json
2022-01-17 01:02:32,914 - INFO - tqdm - reading instances: 0it [00:00, ?it/s]
2022-01-17 01:02:35,040 - INFO - allennlp.common.params - type = from_instances
2022-01-17 01:02:35,040 - INFO - allennlp.common.params - min_count = None
2022-01-17 01:02:35,040 - INFO - allennlp.common.params - max_vocab_size = None
2022-01-17 01:02:35,040 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-01-17 01:02:35,041 - INFO - allennlp.common.params - pretrained_files = None
2022-01-17 01:02:35,041 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-01-17 01:02:35,041 - INFO - allennlp.common.params - tokens_to_add = None
2022-01-17 01:02:35,041 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-01-17 01:02:35,041 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-01-17 01:02:35,041 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-01-17 01:02:35,041 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-01-17 01:02:35,042 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-01-17 01:02:35,224 - INFO - allennlp.common.params - model.type = span_model
2022-01-17 01:02:35,225 - INFO - allennlp.common.params - model.embedder.type = basic
2022-01-17 01:02:35,225 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.type = pretrained_transformer_mismatched
2022-01-17 01:02:35,225 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.model_name = bert-base-uncased
2022-01-17 01:02:35,226 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.max_length = 512
2022-01-17 01:02:35,226 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.train_parameters = True
2022-01-17 01:02:35,226 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.last_layer_only = True
2022-01-17 01:02:35,226 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.gradient_checkpointing = None
2022-01-17 01:02:35,226 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.tokenizer_kwargs = None
2022-01-17 01:02:35,226 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.transformer_kwargs = None
2022-01-17 01:02:38,244 - INFO - allennlp.common.params - model.modules.ner.focal_loss_gamma = 2
2022-01-17 01:02:38,245 - INFO - allennlp.common.params - model.modules.ner.neg_class_weight = -1
2022-01-17 01:02:38,245 - INFO - allennlp.common.params - model.modules.ner.use_bi_affine = False
2022-01-17 01:02:38,245 - INFO - allennlp.common.params - model.modules.ner.use_double_scorer = False
2022-01-17 01:02:38,245 - INFO - allennlp.common.params - model.modules.ner.use_focal_loss = False
2022-01-17 01:02:38,245 - INFO - allennlp.common.params - model.modules.ner.use_gold_for_train_prune_scores = False
2022-01-17 01:02:38,245 - INFO - allennlp.common.params - model.modules.ner.use_single_pool = False
2022-01-17 01:02:38,245 - INFO - allennlp.common.params - model.modules.relation.focal_loss_gamma = 2
2022-01-17 01:02:38,245 - INFO - allennlp.common.params - model.modules.relation.neg_class_weight = -1
2022-01-17 01:02:38,245 - INFO - allennlp.common.params - model.modules.relation.span_length_loss_weight_gamma = 0
2022-01-17 01:02:38,245 - INFO - allennlp.common.params - model.modules.relation.spans_per_word = 0.5
2022-01-17 01:02:38,246 - INFO - allennlp.common.params - model.modules.relation.use_bag_pair_scorer = False
2022-01-17 01:02:38,246 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_classifier = False
2022-01-17 01:02:38,246 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_pruner = False
2022-01-17 01:02:38,246 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_v2 = False
2022-01-17 01:02:38,246 - INFO - allennlp.common.params - model.modules.relation.use_classify_mask_pruner = False
2022-01-17 01:02:38,246 - INFO - allennlp.common.params - model.modules.relation.use_distance_embeds = True
2022-01-17 01:02:38,246 - INFO - allennlp.common.params - model.modules.relation.use_focal_loss = False
2022-01-17 01:02:38,246 - INFO - allennlp.common.params - model.modules.relation.use_ner_scores_for_prune = False
2022-01-17 01:02:38,246 - INFO - allennlp.common.params - model.modules.relation.use_ope_down_project = False
2022-01-17 01:02:38,246 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_cls = False
2022-01-17 01:02:38,246 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_maxpool = False
2022-01-17 01:02:38,246 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_multiply = False
2022-01-17 01:02:38,246 - INFO - allennlp.common.params - model.modules.relation.use_pairwise_down_project = False
2022-01-17 01:02:38,246 - INFO - allennlp.common.params - model.modules.relation.use_pruning = True
2022-01-17 01:02:38,246 - INFO - allennlp.common.params - model.modules.relation.use_single_pool = False
2022-01-17 01:02:38,247 - INFO - allennlp.common.params - model.modules.relation.use_span_loss_for_pruners = False
2022-01-17 01:02:38,247 - INFO - allennlp.common.params - model.modules.relation.use_span_pair_aux_task = False
2022-01-17 01:02:38,247 - INFO - allennlp.common.params - model.modules.relation.use_span_pair_aux_task_after_prune = False
2022-01-17 01:02:38,247 - INFO - allennlp.common.params - model.feature_size = 20
2022-01-17 01:02:38,247 - INFO - allennlp.common.params - model.max_span_width = 8
2022-01-17 01:02:38,247 - INFO - allennlp.common.params - model.target_task = relation
2022-01-17 01:02:38,248 - INFO - allennlp.common.params - model.initializer.regexes.0.1.type = xavier_normal
2022-01-17 01:02:38,248 - INFO - allennlp.common.params - model.initializer.regexes.0.1.gain = 1.0
2022-01-17 01:02:38,248 - INFO - allennlp.common.params - model.initializer.prevent_regexes = None
2022-01-17 01:02:38,249 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.type = xavier_normal
2022-01-17 01:02:38,249 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.gain = 1.0
2022-01-17 01:02:38,249 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.type = xavier_normal
2022-01-17 01:02:38,249 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.gain = 1.0
2022-01-17 01:02:38,249 - INFO - allennlp.common.params - model.module_initializer.prevent_regexes = None
2022-01-17 01:02:38,250 - INFO - allennlp.common.params - model.regularizer = None
2022-01-17 01:02:38,250 - INFO - allennlp.common.params - model.display_metrics = None
2022-01-17 01:02:38,250 - INFO - allennlp.common.params - model.use_ner_embeds = False
2022-01-17 01:02:38,250 - INFO - allennlp.common.params - model.span_extractor_type = endpoint
2022-01-17 01:02:38,250 - INFO - allennlp.common.params - model.use_double_mix_embedder = False
2022-01-17 01:02:38,250 - INFO - allennlp.common.params - model.relation_head_type = proper
2022-01-17 01:02:38,250 - INFO - allennlp.common.params - model.use_span_width_embeds = True
2022-01-17 01:02:38,250 - INFO - allennlp.common.params - model.use_bilstm_after_embedder = False
2022-01-17 01:02:38,251 - INFO - allennlp.common.params - ner.regularizer = None
2022-01-17 01:02:38,251 - INFO - allennlp.common.params - ner.use_bi_affine = False
2022-01-17 01:02:38,251 - INFO - allennlp.common.params - ner.neg_class_weight = -1
2022-01-17 01:02:38,251 - INFO - allennlp.common.params - ner.use_focal_loss = False
2022-01-17 01:02:38,251 - INFO - allennlp.common.params - ner.focal_loss_gamma = 2
2022-01-17 01:02:38,251 - INFO - allennlp.common.params - ner.use_double_scorer = False
2022-01-17 01:02:38,251 - INFO - allennlp.common.params - ner.use_gold_for_train_prune_scores = False
2022-01-17 01:02:38,252 - INFO - allennlp.common.params - ner.use_single_pool = False
2022-01-17 01:02:38,252 - INFO - allennlp.common.params - ner.name = ner_labels
2022-01-17 01:02:38,254 - INFO - allennlp.common.params - relation.regularizer = None
2022-01-17 01:02:38,255 - INFO - allennlp.common.params - relation.serialization_dir = None
2022-01-17 01:02:38,255 - INFO - allennlp.common.params - relation.spans_per_word = 0.5
2022-01-17 01:02:38,255 - INFO - allennlp.common.params - relation.positive_label_weight = 1.0
2022-01-17 01:02:38,255 - INFO - allennlp.common.params - relation.use_distance_embeds = True
2022-01-17 01:02:38,255 - INFO - allennlp.common.params - relation.use_pair_feature_maxpool = False
2022-01-17 01:02:38,255 - INFO - allennlp.common.params - relation.use_pair_feature_cls = False
2022-01-17 01:02:38,255 - INFO - allennlp.common.params - relation.use_bi_affine_classifier = False
2022-01-17 01:02:38,255 - INFO - allennlp.common.params - relation.neg_class_weight = -1
2022-01-17 01:02:38,255 - INFO - allennlp.common.params - relation.span_length_loss_weight_gamma = 0
2022-01-17 01:02:38,256 - INFO - allennlp.common.params - relation.use_bag_pair_scorer = False
2022-01-17 01:02:38,256 - INFO - allennlp.common.params - relation.use_bi_affine_v2 = False
2022-01-17 01:02:38,256 - INFO - allennlp.common.params - relation.use_pruning = True
2022-01-17 01:02:38,256 - INFO - allennlp.common.params - relation.use_single_pool = False
2022-01-17 01:02:38,264 - INFO - allennlp.nn.initializers - Initializing parameters
2022-01-17 01:02:38,265 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.0.weight using .*weight initializer
2022-01-17 01:02:38,267 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.1.weight using .*weight initializer
2022-01-17 01:02:38,268 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.1._module.weight using .*weight initializer
2022-01-17 01:02:38,268 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix
2022-01-17 01:02:38,268 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-01-17 01:02:38,268 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.0.bias
2022-01-17 01:02:38,268 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.1.bias
2022-01-17 01:02:38,268 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.1._module.bias
2022-01-17 01:02:38,268 - INFO - allennlp.nn.initializers - Initializing parameters
2022-01-17 01:02:38,268 - INFO - allennlp.nn.initializers - Initializing d_embedder.embedder.weight using .*weight initializer
2022-01-17 01:02:38,269 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.0.weight using .*weight initializer
2022-01-17 01:02:38,273 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.1.weight using .*weight initializer
2022-01-17 01:02:38,274 - INFO - allennlp.nn.initializers - Initializing _relation_scorers.None__relation_labels.weight using .*weight initializer
2022-01-17 01:02:38,274 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix
2022-01-17 01:02:38,274 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-01-17 01:02:38,274 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.0.bias
2022-01-17 01:02:38,274 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.1.bias
2022-01-17 01:02:38,274 - INFO - allennlp.nn.initializers -    _relation_scorers.None__relation_labels.bias
2022-01-17 01:02:38,274 - INFO - allennlp.nn.initializers - Initializing parameters
2022-01-17 01:02:38,274 - INFO - allennlp.nn.initializers - Initializing _endpoint_span_extractor._span_width_embedding.weight using _span_width_embedding.weight initializer
2022-01-17 01:02:38,277 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-01-17 01:02:38,277 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias
2022-01-17 01:02:38,277 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight
2022-01-17 01:02:38,277 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight
2022-01-17 01:02:38,277 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight
2022-01-17 01:02:38,277 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight
2022-01-17 01:02:38,277 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-01-17 01:02:38,277 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-01-17 01:02:38,277 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-01-17 01:02:38,277 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-01-17 01:02:38,277 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias
2022-01-17 01:02:38,277 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight
2022-01-17 01:02:38,277 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias
2022-01-17 01:02:38,278 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight
2022-01-17 01:02:38,278 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias
2022-01-17 01:02:38,278 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight
2022-01-17 01:02:38,278 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-01-17 01:02:38,278 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-01-17 01:02:38,278 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-01-17 01:02:38,278 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-01-17 01:02:38,278 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias
2022-01-17 01:02:38,278 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight
2022-01-17 01:02:38,278 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-01-17 01:02:38,278 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-01-17 01:02:38,278 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-01-17 01:02:38,278 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-01-17 01:02:38,278 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias
2022-01-17 01:02:38,279 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight
2022-01-17 01:02:38,279 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias
2022-01-17 01:02:38,279 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight
2022-01-17 01:02:38,279 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias
2022-01-17 01:02:38,279 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight
2022-01-17 01:02:38,279 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-01-17 01:02:38,279 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-01-17 01:02:38,279 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-01-17 01:02:38,279 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-01-17 01:02:38,279 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias
2022-01-17 01:02:38,279 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight
2022-01-17 01:02:38,279 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-01-17 01:02:38,279 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-01-17 01:02:38,279 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-01-17 01:02:38,279 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-01-17 01:02:38,279 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias
2022-01-17 01:02:38,280 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight
2022-01-17 01:02:38,280 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias
2022-01-17 01:02:38,280 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight
2022-01-17 01:02:38,280 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias
2022-01-17 01:02:38,280 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight
2022-01-17 01:02:38,280 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-01-17 01:02:38,280 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-01-17 01:02:38,280 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-01-17 01:02:38,280 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-01-17 01:02:38,280 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias
2022-01-17 01:02:38,280 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight
2022-01-17 01:02:38,280 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-01-17 01:02:38,280 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-01-17 01:02:38,280 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-01-17 01:02:38,280 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-01-17 01:02:38,281 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias
2022-01-17 01:02:38,281 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight
2022-01-17 01:02:38,281 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias
2022-01-17 01:02:38,281 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight
2022-01-17 01:02:38,281 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias
2022-01-17 01:02:38,281 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight
2022-01-17 01:02:38,281 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-01-17 01:02:38,281 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-01-17 01:02:38,281 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-01-17 01:02:38,281 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-01-17 01:02:38,281 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias
2022-01-17 01:02:38,281 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight
2022-01-17 01:02:38,281 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-01-17 01:02:38,281 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-01-17 01:02:38,281 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-01-17 01:02:38,281 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-01-17 01:02:38,282 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias
2022-01-17 01:02:38,282 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight
2022-01-17 01:02:38,282 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias
2022-01-17 01:02:38,282 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight
2022-01-17 01:02:38,282 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias
2022-01-17 01:02:38,282 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight
2022-01-17 01:02:38,282 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-01-17 01:02:38,282 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-01-17 01:02:38,282 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-01-17 01:02:38,282 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-01-17 01:02:38,282 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias
2022-01-17 01:02:38,282 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight
2022-01-17 01:02:38,282 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-01-17 01:02:38,282 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-01-17 01:02:38,282 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias
2022-01-17 01:02:38,283 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight
2022-01-17 01:02:38,284 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight
2022-01-17 01:02:38,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias
2022-01-17 01:02:38,286 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight
2022-01-17 01:02:38,287 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.bias
2022-01-17 01:02:38,287 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.weight
2022-01-17 01:02:38,287 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias
2022-01-17 01:02:38,287 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight
2022-01-17 01:02:38,287 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias
2022-01-17 01:02:38,287 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight
2022-01-17 01:02:38,287 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.bias
2022-01-17 01:02:38,287 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.weight
2022-01-17 01:02:38,287 - INFO - allennlp.nn.initializers -    _relation.d_embedder.embedder.weight
2022-01-17 01:02:38,287 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2022-01-17 01:02:38,288 - INFO - allennlp.common.params - data_loader.batch_size = 1
2022-01-17 01:02:38,288 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-01-17 01:02:38,288 - INFO - allennlp.common.params - data_loader.batch_sampler = None
2022-01-17 01:02:38,288 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-01-17 01:02:38,288 - INFO - allennlp.common.params - data_loader.pin_memory = False
2022-01-17 01:02:38,288 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-01-17 01:02:38,288 - INFO - allennlp.common.params - data_loader.timeout = 0
2022-01-17 01:02:38,288 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2022-01-17 01:02:38,288 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2022-01-17 01:02:38,288 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-01-17 01:02:38,288 - INFO - allennlp.common.params - data_loader.sampler.type = random
2022-01-17 01:02:38,289 - INFO - allennlp.common.params - data_loader.sampler.replacement = False
2022-01-17 01:02:38,289 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None
2022-01-17 01:02:38,289 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2022-01-17 01:02:38,289 - INFO - allennlp.common.params - data_loader.batch_size = 1
2022-01-17 01:02:38,289 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-01-17 01:02:38,289 - INFO - allennlp.common.params - data_loader.batch_sampler = None
2022-01-17 01:02:38,289 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-01-17 01:02:38,289 - INFO - allennlp.common.params - data_loader.pin_memory = False
2022-01-17 01:02:38,290 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-01-17 01:02:38,290 - INFO - allennlp.common.params - data_loader.timeout = 0
2022-01-17 01:02:38,290 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2022-01-17 01:02:38,290 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2022-01-17 01:02:38,290 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-01-17 01:02:38,290 - INFO - allennlp.common.params - data_loader.sampler.type = random
2022-01-17 01:02:38,290 - INFO - allennlp.common.params - data_loader.sampler.replacement = False
2022-01-17 01:02:38,290 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None
2022-01-17 01:02:38,290 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2022-01-17 01:02:38,290 - INFO - allennlp.common.params - data_loader.batch_size = 1
2022-01-17 01:02:38,291 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-01-17 01:02:38,291 - INFO - allennlp.common.params - data_loader.batch_sampler = None
2022-01-17 01:02:38,291 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-01-17 01:02:38,291 - INFO - allennlp.common.params - data_loader.pin_memory = False
2022-01-17 01:02:38,291 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-01-17 01:02:38,291 - INFO - allennlp.common.params - data_loader.timeout = 0
2022-01-17 01:02:38,291 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2022-01-17 01:02:38,291 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2022-01-17 01:02:38,291 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-01-17 01:02:38,291 - INFO - allennlp.common.params - data_loader.sampler.type = random
2022-01-17 01:02:38,291 - INFO - allennlp.common.params - data_loader.sampler.replacement = False
2022-01-17 01:02:38,291 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None
2022-01-17 01:02:38,292 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-01-17 01:02:38,292 - INFO - allennlp.common.params - trainer.patience = None
2022-01-17 01:02:38,292 - INFO - allennlp.common.params - trainer.validation_metric = +MEAN__relation_f1
2022-01-17 01:02:38,292 - INFO - allennlp.common.params - trainer.num_epochs = 2
2022-01-17 01:02:38,292 - INFO - allennlp.common.params - trainer.cuda_device = 0
2022-01-17 01:02:38,292 - INFO - allennlp.common.params - trainer.grad_norm = 5
2022-01-17 01:02:38,292 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-01-17 01:02:38,292 - INFO - allennlp.common.params - trainer.distributed = False
2022-01-17 01:02:38,292 - INFO - allennlp.common.params - trainer.world_size = 1
2022-01-17 01:02:38,292 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2022-01-17 01:02:38,292 - INFO - allennlp.common.params - trainer.use_amp = False
2022-01-17 01:02:38,292 - INFO - allennlp.common.params - trainer.no_grad = None
2022-01-17 01:02:38,293 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-01-17 01:02:38,293 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x7fb31aa71250>
2022-01-17 01:02:38,293 - INFO - allennlp.common.params - trainer.moving_average = None
2022-01-17 01:02:38,293 - INFO - allennlp.common.params - trainer.batch_callbacks = None
2022-01-17 01:02:38,293 - INFO - allennlp.common.params - trainer.epoch_callbacks = None
2022-01-17 01:02:38,293 - INFO - allennlp.common.params - trainer.end_callbacks = None
2022-01-17 01:02:38,293 - INFO - allennlp.common.params - trainer.trainer_callbacks = None
2022-01-17 01:02:41,418 - INFO - allennlp.common.params - trainer.optimizer.type = adamw
2022-01-17 01:02:41,419 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.001
2022-01-17 01:02:41,419 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)
2022-01-17 01:02:41,419 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08
2022-01-17 01:02:41,419 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0
2022-01-17 01:02:41,419 - INFO - allennlp.common.params - trainer.optimizer.amsgrad = False
2022-01-17 01:02:41,420 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2022-01-17 01:02:41,420 - INFO - allennlp.training.optimizers - Group 0: ['_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight'], {'finetune': True, 'lr': 5e-05, 'weight_decay': 0.01}
2022-01-17 01:02:41,421 - INFO - allennlp.training.optimizers - Group 1: [], {'lr': 0.01}
2022-01-17 01:02:41,421 - INFO - allennlp.training.optimizers - Group 2: ['_relation._relation_scorers.None__relation_labels.bias', '_ner._ner_scorers.None__ner_labels.1._module.bias', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias', '_endpoint_span_extractor._span_width_embedding.weight', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias', '_relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias', '_ner._ner_scorers.None__ner_labels.1._module.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight', '_relation._relation_scorers.None__relation_labels.weight', '_relation.d_embedder.embedder.weight'], {}
2022-01-17 01:02:41,421 - WARNING - allennlp.training.optimizers - When constructing parameter groups, scalar_parameters does not match any parameter name
2022-01-17 01:02:41,421 - INFO - allennlp.training.optimizers - Number of trainable parameters: 110250945
2022-01-17 01:02:41,423 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-01-17 01:02:41,424 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _endpoint_span_extractor._span_width_embedding.weight
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias
2022-01-17 01:02:41,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight
2022-01-17 01:02:41,426 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-01-17 01:02:41,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight
2022-01-17 01:02:41,428 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-01-17 01:02:41,429 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias
2022-01-17 01:02:41,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight
2022-01-17 01:02:41,431 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-01-17 01:02:41,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight
2022-01-17 01:02:41,433 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias
2022-01-17 01:02:41,434 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight
2022-01-17 01:02:41,434 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias
2022-01-17 01:02:41,434 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.1._module.weight
2022-01-17 01:02:41,434 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.1._module.bias
2022-01-17 01:02:41,434 - INFO - allennlp.common.util - _relation.d_embedder.embedder.weight
2022-01-17 01:02:41,434 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight
2022-01-17 01:02:41,434 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias
2022-01-17 01:02:41,434 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight
2022-01-17 01:02:41,434 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias
2022-01-17 01:02:41,434 - INFO - allennlp.common.util - _relation._relation_scorers.None__relation_labels.weight
2022-01-17 01:02:41,434 - INFO - allennlp.common.util - _relation._relation_scorers.None__relation_labels.bias
2022-01-17 01:02:41,434 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = slanted_triangular
2022-01-17 01:02:41,434 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.cut_frac = 0.1
2022-01-17 01:02:41,434 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.ratio = 32
2022-01-17 01:02:41,435 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1
2022-01-17 01:02:41,435 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.gradual_unfreezing = False
2022-01-17 01:02:41,435 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.discriminative_fine_tuning = False
2022-01-17 01:02:41,435 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.decay_factor = 0.38
2022-01-17 01:02:41,435 - INFO - allennlp.common.params - trainer.checkpointer.type = default
2022-01-17 01:02:41,435 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-01-17 01:02:41,435 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 1
2022-01-17 01:02:41,435 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-01-17 01:02:41,435 - INFO - allennlp.common.params - summary_interval = 100
2022-01-17 01:02:41,435 - INFO - allennlp.common.params - histogram_interval = None
2022-01-17 01:02:41,435 - INFO - allennlp.common.params - batch_size_interval = None
2022-01-17 01:02:41,435 - INFO - allennlp.common.params - should_log_parameter_statistics = True
2022-01-17 01:02:41,435 - INFO - allennlp.common.params - should_log_learning_rate = False
2022-01-17 01:02:41,435 - INFO - allennlp.common.params - get_batch_num_total = None
2022-01-17 01:02:41,437 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled
2022-01-17 01:02:41,449 - INFO - allennlp.training.trainer - Beginning training.
2022-01-17 01:02:41,449 - INFO - allennlp.training.trainer - Epoch 0/1
2022-01-17 01:02:41,449 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.6G
2022-01-17 01:02:41,449 - INFO - allennlp.training.trainer - GPU 0 memory usage: 422M
2022-01-17 01:02:41,450 - INFO - allennlp.training.trainer - Training
2022-01-17 01:02:41,515 - INFO - tqdm - 0%|          | 0/2253 [00:00<?, ?it/s]
2022-01-17 01:02:41,641 - WARNING - allennlp.training.util - Metrics with names beginning with "_" will not be logged to the tqdm progress bar.
2022-01-17 01:02:51,597 - INFO - tqdm - MEAN__relation_precision: 0.0000, MEAN__relation_recall: 0.0000, MEAN__relation_f1: 0.0000, batch_loss: 0.4684, loss: 103.5444 ||:   5%|4         | 107/2253 [00:10<03:55,  9.09it/s]
