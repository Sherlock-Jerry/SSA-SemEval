2022-01-14 14:28:15,424 - INFO - allennlp.common.params - random_seed = 0
2022-01-14 14:28:15,424 - INFO - allennlp.common.params - numpy_seed = 0
2022-01-14 14:28:15,424 - INFO - allennlp.common.params - pytorch_seed = 0
2022-01-14 14:28:15,425 - INFO - allennlp.common.checks - Pytorch version: 1.7.0
2022-01-14 14:28:15,425 - INFO - allennlp.common.params - type = default
2022-01-14 14:28:15,426 - INFO - allennlp.common.params - dataset_reader.type = span_model
2022-01-14 14:28:15,426 - INFO - allennlp.common.params - dataset_reader.lazy = False
2022-01-14 14:28:15,426 - INFO - allennlp.common.params - dataset_reader.cache_directory = None
2022-01-14 14:28:15,426 - INFO - allennlp.common.params - dataset_reader.max_instances = None
2022-01-14 14:28:15,426 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False
2022-01-14 14:28:15,426 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False
2022-01-14 14:28:15,426 - INFO - allennlp.common.params - dataset_reader.max_span_width = 8
2022-01-14 14:28:15,427 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched
2022-01-14 14:28:15,427 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0
2022-01-14 14:28:15,427 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = bert-base-uncased
2022-01-14 14:28:15,427 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags
2022-01-14 14:28:15,427 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512
2022-01-14 14:28:15,427 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None
2022-01-14 14:28:16,160 - INFO - allennlp.common.params - train_data_path = /content/SSA-SemEval/Span-ASTE-main/model_outputs/aste_darmstadt_unis_6e01f1772af7bbbef56b8ba0511d931f/train.json
2022-01-14 14:28:16,161 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7fd9fcc25fd0>
2022-01-14 14:28:16,161 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-01-14 14:28:16,161 - INFO - allennlp.common.params - validation_dataset_reader = None
2022-01-14 14:28:16,161 - INFO - allennlp.common.params - validation_data_path = /content/SSA-SemEval/Span-ASTE-main/model_outputs/aste_darmstadt_unis_6e01f1772af7bbbef56b8ba0511d931f/dev.json
2022-01-14 14:28:16,162 - INFO - allennlp.common.params - validation_data_loader = None
2022-01-14 14:28:16,162 - INFO - allennlp.common.params - test_data_path = /content/SSA-SemEval/Span-ASTE-main/model_outputs/aste_darmstadt_unis_6e01f1772af7bbbef56b8ba0511d931f/test.json
2022-01-14 14:28:16,162 - INFO - allennlp.common.params - evaluate_on_test = False
2022-01-14 14:28:16,162 - INFO - allennlp.common.params - batch_weight_key = 
2022-01-14 14:28:16,162 - INFO - allennlp.training.util - Reading training data from /content/SSA-SemEval/Span-ASTE-main/model_outputs/aste_darmstadt_unis_6e01f1772af7bbbef56b8ba0511d931f/train.json
2022-01-14 14:28:16,163 - INFO - tqdm - reading instances: 0it [00:00, ?it/s]
2022-01-14 14:28:26,201 - INFO - tqdm - reading instances: 1028it [00:10, 116.97it/s]
2022-01-14 14:28:36,219 - INFO - tqdm - reading instances: 2181it [00:20, 118.18it/s]
2022-01-14 14:28:36,773 - INFO - allennlp.training.util - Reading validation data from /content/SSA-SemEval/Span-ASTE-main/model_outputs/aste_darmstadt_unis_6e01f1772af7bbbef56b8ba0511d931f/dev.json
2022-01-14 14:28:36,773 - INFO - tqdm - reading instances: 0it [00:00, ?it/s]
2022-01-14 14:28:38,578 - INFO - allennlp.training.util - Reading test data from /content/SSA-SemEval/Span-ASTE-main/model_outputs/aste_darmstadt_unis_6e01f1772af7bbbef56b8ba0511d931f/test.json
2022-01-14 14:28:38,579 - INFO - tqdm - reading instances: 0it [00:00, ?it/s]
2022-01-14 14:28:40,745 - INFO - allennlp.common.params - type = from_instances
2022-01-14 14:28:40,745 - INFO - allennlp.common.params - min_count = None
2022-01-14 14:28:40,745 - INFO - allennlp.common.params - max_vocab_size = None
2022-01-14 14:28:40,746 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-01-14 14:28:40,746 - INFO - allennlp.common.params - pretrained_files = None
2022-01-14 14:28:40,746 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-01-14 14:28:40,746 - INFO - allennlp.common.params - tokens_to_add = None
2022-01-14 14:28:40,746 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-01-14 14:28:40,746 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-01-14 14:28:40,746 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-01-14 14:28:40,746 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-01-14 14:28:40,747 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-01-14 14:28:40,940 - INFO - allennlp.common.params - model.type = span_model
2022-01-14 14:28:40,940 - INFO - allennlp.common.params - model.embedder.type = basic
2022-01-14 14:28:40,941 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.type = pretrained_transformer_mismatched
2022-01-14 14:28:40,941 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.model_name = bert-base-uncased
2022-01-14 14:28:40,941 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.max_length = 512
2022-01-14 14:28:40,941 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.train_parameters = True
2022-01-14 14:28:40,941 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.last_layer_only = True
2022-01-14 14:28:40,941 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.gradient_checkpointing = None
2022-01-14 14:28:40,941 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.tokenizer_kwargs = None
2022-01-14 14:28:40,942 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.transformer_kwargs = None
2022-01-14 14:28:43,960 - INFO - allennlp.common.params - model.modules.ner.focal_loss_gamma = 2
2022-01-14 14:28:43,960 - INFO - allennlp.common.params - model.modules.ner.neg_class_weight = -1
2022-01-14 14:28:43,960 - INFO - allennlp.common.params - model.modules.ner.use_bi_affine = False
2022-01-14 14:28:43,960 - INFO - allennlp.common.params - model.modules.ner.use_double_scorer = False
2022-01-14 14:28:43,960 - INFO - allennlp.common.params - model.modules.ner.use_focal_loss = False
2022-01-14 14:28:43,960 - INFO - allennlp.common.params - model.modules.ner.use_gold_for_train_prune_scores = False
2022-01-14 14:28:43,960 - INFO - allennlp.common.params - model.modules.ner.use_single_pool = False
2022-01-14 14:28:43,960 - INFO - allennlp.common.params - model.modules.relation.focal_loss_gamma = 2
2022-01-14 14:28:43,960 - INFO - allennlp.common.params - model.modules.relation.neg_class_weight = -1
2022-01-14 14:28:43,961 - INFO - allennlp.common.params - model.modules.relation.span_length_loss_weight_gamma = 0
2022-01-14 14:28:43,961 - INFO - allennlp.common.params - model.modules.relation.spans_per_word = 0.5
2022-01-14 14:28:43,961 - INFO - allennlp.common.params - model.modules.relation.use_bag_pair_scorer = False
2022-01-14 14:28:43,961 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_classifier = False
2022-01-14 14:28:43,961 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_pruner = False
2022-01-14 14:28:43,961 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_v2 = False
2022-01-14 14:28:43,961 - INFO - allennlp.common.params - model.modules.relation.use_classify_mask_pruner = False
2022-01-14 14:28:43,961 - INFO - allennlp.common.params - model.modules.relation.use_distance_embeds = True
2022-01-14 14:28:43,961 - INFO - allennlp.common.params - model.modules.relation.use_focal_loss = False
2022-01-14 14:28:43,961 - INFO - allennlp.common.params - model.modules.relation.use_ner_scores_for_prune = False
2022-01-14 14:28:43,961 - INFO - allennlp.common.params - model.modules.relation.use_ope_down_project = False
2022-01-14 14:28:43,961 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_cls = False
2022-01-14 14:28:43,961 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_maxpool = False
2022-01-14 14:28:43,961 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_multiply = False
2022-01-14 14:28:43,962 - INFO - allennlp.common.params - model.modules.relation.use_pairwise_down_project = False
2022-01-14 14:28:43,962 - INFO - allennlp.common.params - model.modules.relation.use_pruning = True
2022-01-14 14:28:43,962 - INFO - allennlp.common.params - model.modules.relation.use_single_pool = False
2022-01-14 14:28:43,962 - INFO - allennlp.common.params - model.modules.relation.use_span_loss_for_pruners = False
2022-01-14 14:28:43,962 - INFO - allennlp.common.params - model.modules.relation.use_span_pair_aux_task = False
2022-01-14 14:28:43,962 - INFO - allennlp.common.params - model.modules.relation.use_span_pair_aux_task_after_prune = False
2022-01-14 14:28:43,962 - INFO - allennlp.common.params - model.feature_size = 20
2022-01-14 14:28:43,962 - INFO - allennlp.common.params - model.max_span_width = 8
2022-01-14 14:28:43,962 - INFO - allennlp.common.params - model.target_task = relation
2022-01-14 14:28:43,963 - INFO - allennlp.common.params - model.initializer.regexes.0.1.type = xavier_normal
2022-01-14 14:28:43,963 - INFO - allennlp.common.params - model.initializer.regexes.0.1.gain = 1.0
2022-01-14 14:28:43,963 - INFO - allennlp.common.params - model.initializer.prevent_regexes = None
2022-01-14 14:28:43,964 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.type = xavier_normal
2022-01-14 14:28:43,964 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.gain = 1.0
2022-01-14 14:28:43,964 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.type = xavier_normal
2022-01-14 14:28:43,964 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.gain = 1.0
2022-01-14 14:28:43,965 - INFO - allennlp.common.params - model.module_initializer.prevent_regexes = None
2022-01-14 14:28:43,965 - INFO - allennlp.common.params - model.regularizer = None
2022-01-14 14:28:43,965 - INFO - allennlp.common.params - model.display_metrics = None
2022-01-14 14:28:43,965 - INFO - allennlp.common.params - model.use_ner_embeds = False
2022-01-14 14:28:43,965 - INFO - allennlp.common.params - model.span_extractor_type = endpoint
2022-01-14 14:28:43,965 - INFO - allennlp.common.params - model.use_double_mix_embedder = False
2022-01-14 14:28:43,965 - INFO - allennlp.common.params - model.relation_head_type = proper
2022-01-14 14:28:43,965 - INFO - allennlp.common.params - model.use_span_width_embeds = True
2022-01-14 14:28:43,966 - INFO - allennlp.common.params - model.use_bilstm_after_embedder = False
2022-01-14 14:28:43,966 - INFO - allennlp.common.params - ner.regularizer = None
2022-01-14 14:28:43,966 - INFO - allennlp.common.params - ner.use_bi_affine = False
2022-01-14 14:28:43,966 - INFO - allennlp.common.params - ner.neg_class_weight = -1
2022-01-14 14:28:43,966 - INFO - allennlp.common.params - ner.use_focal_loss = False
2022-01-14 14:28:43,967 - INFO - allennlp.common.params - ner.focal_loss_gamma = 2
2022-01-14 14:28:43,967 - INFO - allennlp.common.params - ner.use_double_scorer = False
2022-01-14 14:28:43,967 - INFO - allennlp.common.params - ner.use_gold_for_train_prune_scores = False
2022-01-14 14:28:43,967 - INFO - allennlp.common.params - ner.use_single_pool = False
2022-01-14 14:28:43,967 - INFO - allennlp.common.params - ner.name = ner_labels
2022-01-14 14:28:43,970 - INFO - allennlp.common.params - relation.regularizer = None
2022-01-14 14:28:43,970 - INFO - allennlp.common.params - relation.serialization_dir = None
2022-01-14 14:28:43,970 - INFO - allennlp.common.params - relation.spans_per_word = 0.5
2022-01-14 14:28:43,970 - INFO - allennlp.common.params - relation.positive_label_weight = 1.0
2022-01-14 14:28:43,971 - INFO - allennlp.common.params - relation.use_distance_embeds = True
2022-01-14 14:28:43,971 - INFO - allennlp.common.params - relation.use_pair_feature_maxpool = False
2022-01-14 14:28:43,971 - INFO - allennlp.common.params - relation.use_pair_feature_cls = False
2022-01-14 14:28:43,971 - INFO - allennlp.common.params - relation.use_bi_affine_classifier = False
2022-01-14 14:28:43,971 - INFO - allennlp.common.params - relation.neg_class_weight = -1
2022-01-14 14:28:43,971 - INFO - allennlp.common.params - relation.span_length_loss_weight_gamma = 0
2022-01-14 14:28:43,971 - INFO - allennlp.common.params - relation.use_bag_pair_scorer = False
2022-01-14 14:28:43,971 - INFO - allennlp.common.params - relation.use_bi_affine_v2 = False
2022-01-14 14:28:43,971 - INFO - allennlp.common.params - relation.use_pruning = True
2022-01-14 14:28:43,972 - INFO - allennlp.common.params - relation.use_single_pool = False
2022-01-14 14:28:43,981 - INFO - allennlp.nn.initializers - Initializing parameters
2022-01-14 14:28:43,981 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.0.weight using .*weight initializer
2022-01-14 14:28:43,984 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.1.weight using .*weight initializer
2022-01-14 14:28:43,984 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.1._module.weight using .*weight initializer
2022-01-14 14:28:43,985 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix
2022-01-14 14:28:43,985 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-01-14 14:28:43,985 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.0.bias
2022-01-14 14:28:43,985 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.1.bias
2022-01-14 14:28:43,985 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.1._module.bias
2022-01-14 14:28:43,985 - INFO - allennlp.nn.initializers - Initializing parameters
2022-01-14 14:28:43,985 - INFO - allennlp.nn.initializers - Initializing d_embedder.embedder.weight using .*weight initializer
2022-01-14 14:28:43,985 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.0.weight using .*weight initializer
2022-01-14 14:28:43,991 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.1.weight using .*weight initializer
2022-01-14 14:28:43,991 - INFO - allennlp.nn.initializers - Initializing _relation_scorers.None__relation_labels.weight using .*weight initializer
2022-01-14 14:28:43,992 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix
2022-01-14 14:28:43,992 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-01-14 14:28:43,992 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.0.bias
2022-01-14 14:28:43,992 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.1.bias
2022-01-14 14:28:43,992 - INFO - allennlp.nn.initializers -    _relation_scorers.None__relation_labels.bias
2022-01-14 14:28:43,992 - INFO - allennlp.nn.initializers - Initializing parameters
2022-01-14 14:28:43,992 - INFO - allennlp.nn.initializers - Initializing _endpoint_span_extractor._span_width_embedding.weight using _span_width_embedding.weight initializer
2022-01-14 14:28:43,994 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-01-14 14:28:43,995 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias
2022-01-14 14:28:43,995 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight
2022-01-14 14:28:43,995 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight
2022-01-14 14:28:43,995 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight
2022-01-14 14:28:43,995 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight
2022-01-14 14:28:43,995 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-01-14 14:28:43,995 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-01-14 14:28:43,995 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-01-14 14:28:43,995 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-01-14 14:28:43,995 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias
2022-01-14 14:28:43,995 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight
2022-01-14 14:28:43,995 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias
2022-01-14 14:28:43,995 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight
2022-01-14 14:28:43,995 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias
2022-01-14 14:28:43,996 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight
2022-01-14 14:28:43,996 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-01-14 14:28:43,996 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-01-14 14:28:43,996 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-01-14 14:28:43,996 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-01-14 14:28:43,996 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias
2022-01-14 14:28:43,996 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight
2022-01-14 14:28:43,996 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-01-14 14:28:43,996 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-01-14 14:28:43,996 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-01-14 14:28:43,996 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-01-14 14:28:43,996 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias
2022-01-14 14:28:43,996 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight
2022-01-14 14:28:43,996 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias
2022-01-14 14:28:43,997 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight
2022-01-14 14:28:43,997 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias
2022-01-14 14:28:43,997 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight
2022-01-14 14:28:43,997 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-01-14 14:28:43,997 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-01-14 14:28:43,997 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-01-14 14:28:43,997 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-01-14 14:28:43,997 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias
2022-01-14 14:28:43,997 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight
2022-01-14 14:28:43,997 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-01-14 14:28:43,997 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-01-14 14:28:43,997 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-01-14 14:28:43,997 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-01-14 14:28:43,998 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias
2022-01-14 14:28:43,998 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight
2022-01-14 14:28:43,998 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias
2022-01-14 14:28:43,998 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight
2022-01-14 14:28:43,998 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias
2022-01-14 14:28:43,998 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight
2022-01-14 14:28:43,998 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-01-14 14:28:43,998 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-01-14 14:28:43,998 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-01-14 14:28:43,998 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-01-14 14:28:43,998 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias
2022-01-14 14:28:43,998 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight
2022-01-14 14:28:43,998 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-01-14 14:28:43,998 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-01-14 14:28:43,999 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-01-14 14:28:43,999 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-01-14 14:28:43,999 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias
2022-01-14 14:28:43,999 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight
2022-01-14 14:28:43,999 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias
2022-01-14 14:28:43,999 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight
2022-01-14 14:28:43,999 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias
2022-01-14 14:28:43,999 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight
2022-01-14 14:28:43,999 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-01-14 14:28:43,999 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-01-14 14:28:43,999 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-01-14 14:28:43,999 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-01-14 14:28:43,999 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias
2022-01-14 14:28:43,999 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight
2022-01-14 14:28:44,000 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-01-14 14:28:44,000 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-01-14 14:28:44,000 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-01-14 14:28:44,000 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-01-14 14:28:44,000 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias
2022-01-14 14:28:44,000 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight
2022-01-14 14:28:44,000 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias
2022-01-14 14:28:44,000 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight
2022-01-14 14:28:44,000 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias
2022-01-14 14:28:44,000 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight
2022-01-14 14:28:44,000 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-01-14 14:28:44,000 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-01-14 14:28:44,000 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-01-14 14:28:44,000 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-01-14 14:28:44,000 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias
2022-01-14 14:28:44,001 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-01-14 14:28:44,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-01-14 14:28:44,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight
2022-01-14 14:28:44,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.bias
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.weight
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.bias
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.weight
2022-01-14 14:28:44,005 - INFO - allennlp.nn.initializers -    _relation.d_embedder.embedder.weight
2022-01-14 14:28:44,006 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2022-01-14 14:28:44,006 - INFO - allennlp.common.params - data_loader.batch_size = 1
2022-01-14 14:28:44,006 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-01-14 14:28:44,006 - INFO - allennlp.common.params - data_loader.batch_sampler = None
2022-01-14 14:28:44,006 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-01-14 14:28:44,006 - INFO - allennlp.common.params - data_loader.pin_memory = False
2022-01-14 14:28:44,007 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-01-14 14:28:44,007 - INFO - allennlp.common.params - data_loader.timeout = 0
2022-01-14 14:28:44,007 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2022-01-14 14:28:44,007 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2022-01-14 14:28:44,007 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-01-14 14:28:44,007 - INFO - allennlp.common.params - data_loader.sampler.type = random
2022-01-14 14:28:44,007 - INFO - allennlp.common.params - data_loader.sampler.replacement = False
2022-01-14 14:28:44,007 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None
2022-01-14 14:28:44,007 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2022-01-14 14:28:44,008 - INFO - allennlp.common.params - data_loader.batch_size = 1
2022-01-14 14:28:44,008 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-01-14 14:28:44,008 - INFO - allennlp.common.params - data_loader.batch_sampler = None
2022-01-14 14:28:44,008 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-01-14 14:28:44,008 - INFO - allennlp.common.params - data_loader.pin_memory = False
2022-01-14 14:28:44,008 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-01-14 14:28:44,008 - INFO - allennlp.common.params - data_loader.timeout = 0
2022-01-14 14:28:44,008 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2022-01-14 14:28:44,008 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2022-01-14 14:28:44,008 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-01-14 14:28:44,008 - INFO - allennlp.common.params - data_loader.sampler.type = random
2022-01-14 14:28:44,008 - INFO - allennlp.common.params - data_loader.sampler.replacement = False
2022-01-14 14:28:44,008 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None
2022-01-14 14:28:44,009 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2022-01-14 14:28:44,009 - INFO - allennlp.common.params - data_loader.batch_size = 1
2022-01-14 14:28:44,009 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-01-14 14:28:44,009 - INFO - allennlp.common.params - data_loader.batch_sampler = None
2022-01-14 14:28:44,009 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-01-14 14:28:44,009 - INFO - allennlp.common.params - data_loader.pin_memory = False
2022-01-14 14:28:44,009 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-01-14 14:28:44,009 - INFO - allennlp.common.params - data_loader.timeout = 0
2022-01-14 14:28:44,009 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2022-01-14 14:28:44,009 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2022-01-14 14:28:44,009 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-01-14 14:28:44,009 - INFO - allennlp.common.params - data_loader.sampler.type = random
2022-01-14 14:28:44,010 - INFO - allennlp.common.params - data_loader.sampler.replacement = False
2022-01-14 14:28:44,010 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None
2022-01-14 14:28:44,010 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-01-14 14:28:44,010 - INFO - allennlp.common.params - trainer.patience = None
2022-01-14 14:28:44,010 - INFO - allennlp.common.params - trainer.validation_metric = +MEAN__relation_f1
2022-01-14 14:28:44,010 - INFO - allennlp.common.params - trainer.num_epochs = 2
2022-01-14 14:28:44,011 - INFO - allennlp.common.params - trainer.cuda_device = 0
2022-01-14 14:28:44,011 - INFO - allennlp.common.params - trainer.grad_norm = 5
2022-01-14 14:28:44,011 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-01-14 14:28:44,011 - INFO - allennlp.common.params - trainer.distributed = False
2022-01-14 14:28:44,011 - INFO - allennlp.common.params - trainer.world_size = 1
2022-01-14 14:28:44,011 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2022-01-14 14:28:44,011 - INFO - allennlp.common.params - trainer.use_amp = False
2022-01-14 14:28:44,011 - INFO - allennlp.common.params - trainer.no_grad = None
2022-01-14 14:28:44,011 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-01-14 14:28:44,011 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x7fd9fcc83350>
2022-01-14 14:28:44,011 - INFO - allennlp.common.params - trainer.moving_average = None
2022-01-14 14:28:44,011 - INFO - allennlp.common.params - trainer.batch_callbacks = None
2022-01-14 14:28:44,012 - INFO - allennlp.common.params - trainer.epoch_callbacks = None
2022-01-14 14:28:44,012 - INFO - allennlp.common.params - trainer.end_callbacks = None
2022-01-14 14:28:44,012 - INFO - allennlp.common.params - trainer.trainer_callbacks = None
2022-01-14 14:28:47,159 - INFO - allennlp.common.params - trainer.optimizer.type = adamw
2022-01-14 14:28:47,159 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.001
2022-01-14 14:28:47,159 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)
2022-01-14 14:28:47,159 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08
2022-01-14 14:28:47,160 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0
2022-01-14 14:28:47,160 - INFO - allennlp.common.params - trainer.optimizer.amsgrad = False
2022-01-14 14:28:47,161 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2022-01-14 14:28:47,161 - INFO - allennlp.training.optimizers - Group 0: ['_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias'], {'finetune': True, 'lr': 5e-05, 'weight_decay': 0.01}
2022-01-14 14:28:47,161 - INFO - allennlp.training.optimizers - Group 1: [], {'lr': 0.01}
2022-01-14 14:28:47,161 - INFO - allennlp.training.optimizers - Group 2: ['_ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight', '_relation._relation_scorers.None__relation_labels.bias', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias', '_endpoint_span_extractor._span_width_embedding.weight', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias', '_relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight', '_relation.d_embedder.embedder.weight', '_relation._relation_scorers.None__relation_labels.weight', '_ner._ner_scorers.None__ner_labels.1._module.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias', '_relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias', '_ner._ner_scorers.None__ner_labels.1._module.bias'], {}
2022-01-14 14:28:47,161 - WARNING - allennlp.training.optimizers - When constructing parameter groups, scalar_parameters does not match any parameter name
2022-01-14 14:28:47,161 - INFO - allennlp.training.optimizers - Number of trainable parameters: 110250945
2022-01-14 14:28:47,163 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-01-14 14:28:47,165 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-01-14 14:28:47,165 - INFO - allennlp.common.util - _endpoint_span_extractor._span_width_embedding.weight
2022-01-14 14:28:47,165 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight
2022-01-14 14:28:47,165 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight
2022-01-14 14:28:47,165 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight
2022-01-14 14:28:47,165 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight
2022-01-14 14:28:47,165 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias
2022-01-14 14:28:47,165 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight
2022-01-14 14:28:47,165 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias
2022-01-14 14:28:47,165 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight
2022-01-14 14:28:47,165 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias
2022-01-14 14:28:47,165 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight
2022-01-14 14:28:47,165 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias
2022-01-14 14:28:47,165 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-01-14 14:28:47,165 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-01-14 14:28:47,165 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-01-14 14:28:47,165 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-01-14 14:28:47,166 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-01-14 14:28:47,167 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-01-14 14:28:47,168 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias
2022-01-14 14:28:47,169 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias
2022-01-14 14:28:47,170 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight
2022-01-14 14:28:47,171 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight
2022-01-14 14:28:47,172 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight
2022-01-14 14:28:47,173 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias
2022-01-14 14:28:47,174 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight
2022-01-14 14:28:47,174 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias
2022-01-14 14:28:47,174 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.1._module.weight
2022-01-14 14:28:47,174 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.1._module.bias
2022-01-14 14:28:47,174 - INFO - allennlp.common.util - _relation.d_embedder.embedder.weight
2022-01-14 14:28:47,174 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight
2022-01-14 14:28:47,174 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias
2022-01-14 14:28:47,174 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight
2022-01-14 14:28:47,174 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias
2022-01-14 14:28:47,174 - INFO - allennlp.common.util - _relation._relation_scorers.None__relation_labels.weight
2022-01-14 14:28:47,174 - INFO - allennlp.common.util - _relation._relation_scorers.None__relation_labels.bias
2022-01-14 14:28:47,174 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = slanted_triangular
2022-01-14 14:28:47,174 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.cut_frac = 0.1
2022-01-14 14:28:47,174 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.ratio = 32
2022-01-14 14:28:47,174 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1
2022-01-14 14:28:47,175 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.gradual_unfreezing = False
2022-01-14 14:28:47,175 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.discriminative_fine_tuning = False
2022-01-14 14:28:47,175 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.decay_factor = 0.38
2022-01-14 14:28:47,175 - INFO - allennlp.common.params - trainer.checkpointer.type = default
2022-01-14 14:28:47,175 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2022-01-14 14:28:47,175 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 1
2022-01-14 14:28:47,175 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2022-01-14 14:28:47,175 - INFO - allennlp.common.params - summary_interval = 100
2022-01-14 14:28:47,175 - INFO - allennlp.common.params - histogram_interval = None
2022-01-14 14:28:47,175 - INFO - allennlp.common.params - batch_size_interval = None
2022-01-14 14:28:47,175 - INFO - allennlp.common.params - should_log_parameter_statistics = True
2022-01-14 14:28:47,175 - INFO - allennlp.common.params - should_log_learning_rate = False
2022-01-14 14:28:47,175 - INFO - allennlp.common.params - get_batch_num_total = None
2022-01-14 14:28:47,177 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled
2022-01-14 14:28:47,189 - INFO - allennlp.training.trainer - Beginning training.
2022-01-14 14:28:47,189 - INFO - allennlp.training.trainer - Epoch 0/1
2022-01-14 14:28:47,189 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.6G
2022-01-14 14:28:47,189 - INFO - allennlp.training.trainer - GPU 0 memory usage: 422M
2022-01-14 14:28:47,190 - INFO - allennlp.training.trainer - Training
2022-01-14 14:28:47,217 - INFO - tqdm - 0%|          | 0/2253 [00:00<?, ?it/s]
2022-01-14 14:28:47,244 - CRITICAL - root - Uncaught exception
Traceback (most recent call last):
  File "/usr/local/bin/allennlp", line 8, in <module>
    sys.exit(run())
  File "/usr/local/lib/python3.7/dist-packages/allennlp/__main__.py", line 34, in run
    main(prog="allennlp")
  File "/usr/local/lib/python3.7/dist-packages/allennlp/commands/__init__.py", line 118, in main
    args.func(args)
  File "/usr/local/lib/python3.7/dist-packages/allennlp/commands/train.py", line 119, in train_model_from_args
    file_friendly_logging=args.file_friendly_logging,
  File "/usr/local/lib/python3.7/dist-packages/allennlp/commands/train.py", line 178, in train_model_from_file
    file_friendly_logging=file_friendly_logging,
  File "/usr/local/lib/python3.7/dist-packages/allennlp/commands/train.py", line 242, in train_model
    file_friendly_logging=file_friendly_logging,
  File "/usr/local/lib/python3.7/dist-packages/allennlp/commands/train.py", line 466, in _train_worker
    metrics = train_loop.run()
  File "/usr/local/lib/python3.7/dist-packages/allennlp/commands/train.py", line 528, in run
    return self.trainer.train()
  File "/usr/local/lib/python3.7/dist-packages/allennlp/training/trainer.py", line 966, in train
    return self._try_train()
  File "/usr/local/lib/python3.7/dist-packages/allennlp/training/trainer.py", line 1001, in _try_train
    train_metrics = self._train_epoch(epoch)
  File "/usr/local/lib/python3.7/dist-packages/allennlp/training/trainer.py", line 681, in _train_epoch
    for batch_group in batch_group_generator_tqdm:
  File "/usr/local/lib/python3.7/dist-packages/tqdm/std.py", line 1180, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.7/dist-packages/allennlp/common/util.py", line 138, in lazy_groups_of
    s = list(islice(iterator, group_size))
  File "/usr/local/lib/python3.7/dist-packages/allennlp/data/dataloader.py", line 115, in __iter__
    yield from super().__iter__()
  File "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py", line 435, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py", line 475, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py", line 47, in fetch
    return self.collate_fn(data)
  File "/usr/local/lib/python3.7/dist-packages/allennlp/data/dataloader.py", line 18, in allennlp_collate
    return batch.as_tensor_dict(batch.get_padding_lengths())
  File "/usr/local/lib/python3.7/dist-packages/allennlp/data/batch.py", line 141, in as_tensor_dict
    for field, tensors in instance.as_tensor_dict(lengths_to_use).items():
  File "/usr/local/lib/python3.7/dist-packages/allennlp/data/instance.py", line 101, in as_tensor_dict
    tensors[field_name] = field.as_tensor(padding_lengths[field_name])
  File "/usr/local/lib/python3.7/dist-packages/allennlp/data/fields/list_field.py", line 98, in as_tensor
    padded_fields = [field.as_tensor(child_padding_lengths) for field in padded_field_list]
  File "/usr/local/lib/python3.7/dist-packages/allennlp/data/fields/list_field.py", line 98, in <listcomp>
    padded_fields = [field.as_tensor(child_padding_lengths) for field in padded_field_list]
  File "/usr/local/lib/python3.7/dist-packages/allennlp/data/fields/adjacency_field.py", line 129, in as_tensor
    tensor[index] = label
IndexError: too many indices for tensor of dimension 2
